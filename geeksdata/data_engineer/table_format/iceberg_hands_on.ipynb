{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb23f707-971f-4cc7-b495-be6c3383312b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from datetime import datetime\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2d0371-509f-46ed-ac9e-1842cf40110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /home/jovyan/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.6.1.jar pyspark-shell'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "\n",
    "from infra import get_spark_session\n",
    "\n",
    "# Constant\n",
    "CATALOG_NAME = 'optimus'\n",
    "SCHEMA_NAME = 'bronze'\n",
    "TABLE_NAME = 'customers'\n",
    "\n",
    "\n",
    "# Initialize Spark with Iceberg Configuration, including Jar files and Catalog name\n",
    "# NOTE: This config is used for Hadoop local file. If you want to use Iceberg in Object Storage, let's read the official document\n",
    "def build_iceberg_conf(kwargs={}):\n",
    "    catalog_name = kwargs.get(\"catalog_name\", CATALOG_NAME)\n",
    "    return (\n",
    "        SparkConf()\n",
    "        .setAppName(\"Thesis's Application\")\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\n",
    "        .set(f'spark.sql.catalog.{catalog_name}', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set(f'spark.sql.catalog.{catalog_name}.type', 'hadoop')\n",
    "        .set(f'spark.sql.catalog.{catalog_name}.warehouse', '/home/jovyan/warehouse')\n",
    "        # .set(f'spark.sql.catalog.{catalog_name}.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "    )\n",
    "spark = get_spark_session(build_iceberg_conf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4638c02-bffb-4c9a-8f69-fedbafe64b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part 1: Create Iceberg table in Local environment\n",
    "'''\n",
    "# This is the DDL for Demo table\n",
    "iceberg_tbl = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{catalog_name}`.`{schema_name}`.`{table_name}`\n",
    "    ( \n",
    "        customer_id BIGINT,\n",
    "        name        STRING,\n",
    "        email       STRING,\n",
    "        country     STRING\n",
    "    )\n",
    "USING iceberg\n",
    "PARTITIONED BY (`country`);\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(iceberg_tbl.format(\n",
    "        catalog_name=CATALOG_NAME,\n",
    "        schema_name=SCHEMA_NAME,\n",
    "        table_name=TABLE_NAME)\n",
    ").show()\n",
    "\n",
    "# Use Catalog optimus.bronze\n",
    "spark.sql('USE optimus.bronze;').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad724d46-8695-4c93-abe3-3eb289c6da1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+---------+-------------------+\n",
      "|made_current_at|snapshot_id|parent_id|is_current_ancestor|\n",
      "+---------------+-----------+---------+-------------------+\n",
      "+---------------+-----------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from optimus.bronze.customers.history').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba46797e-28d1-4463-896e-d36a7b7c23fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO optimus.bronze.customers VALUES \n",
    "        (1, 'Alice', 'alice@example.com', 'US'),\n",
    "        (2, 'Bob',   'bob@example.com',   'CA'),\n",
    "        (3, 'Carlos','carlos@example.com','US');\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fe26d03-b8c5-45eb-b5b4-a0a2119f4955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+-------------------+\n",
      "|     made_current_at|        snapshot_id|parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+---------+-------------------+\n",
      "|2025-05-18 01:54:...|2965786013090896756|     NULL|               true|\n",
      "+--------------------+-------------------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query history\n",
    "spark.sql('select * from optimus.bronze.customers.history').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19a4a00d-85ce-4878-a8b1-e9916e052d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+---------+---------+--------------------+--------------------+\n",
      "|2025-05-18 01:54:...|2965786013090896756|     NULL|   append|/home/jovyan/ware...|{spark.app.id -> ...|\n",
      "+--------------------+-------------------+---------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Snapshot\n",
    "spark.sql('select * from optimus.bronze.customers.snapshots').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b4192e6-e4ee-48b1-bde1-70d100efee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+\n",
      "|           file_path|partition|record_count|\n",
      "+--------------------+---------+------------+\n",
      "|/home/jovyan/ware...|     {US}|           2|\n",
      "|/home/jovyan/ware...|     {CA}|           1|\n",
      "+--------------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query data file\n",
    "spark.sql('select file_path, partition, record_count from optimus.bronze.customers.files').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3b927-70f1-443a-adc6-ba038934f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
